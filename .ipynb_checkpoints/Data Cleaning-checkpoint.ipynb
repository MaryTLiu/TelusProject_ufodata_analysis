{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12665f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import pycountry\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent=\"http\")\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "# load data\n",
    "ufodata = pd.read_csv('nuforc_reports.csv', engine='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d828f",
   "metadata": {},
   "source": [
    "# Data Cleaning  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5458a3e",
   "metadata": {},
   "source": [
    "### Data cleaning procedures:\n",
    "\n",
    "* Columns selection.\n",
    "* Rows duplication removal.\n",
    "* Missing values imputation and removal.\n",
    "    * Impute state using NLP.\n",
    "    * Impute geocoordinates (city_latitude, city_longitude).\n",
    "* Correct the string format in the 'city' column.\n",
    "* Label consolidation in the 'shape' column.\n",
    "* Convert 'date_time' column to standard datetime format.\n",
    "* Convert 'duration' column into interval of seconds.\n",
    "* Add a 'country_code' column in ISO-3166-1 alpha2 format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d308920",
   "metadata": {},
   "source": [
    "#### Select the columns to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9880a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posted and reported times are not useful, so drop these 2 colunms,\n",
    "# keep only the datetime where the sighting is occurred\n",
    "ufodata.drop(['stats', 'posted'], axis=1, inplace=True)\n",
    "\n",
    "# report_link is also not useful, so drop that as well\n",
    "ufodata.drop('report_link', axis=1, inplace=True)\n",
    "\n",
    "# drop 'summary' and 'text' columns\n",
    "ufodata.drop(['summary', 'text'], axis=1, inplace=True)\n",
    "\n",
    "# drop rows where all entries are null\n",
    "ufodata.dropna(how='all', inplace=True)\n",
    "\n",
    "# remove the rows where date_time is null\n",
    "ufodata = ufodata[ufodata['date_time'].notnull()]\n",
    "\n",
    "# remove duplications\n",
    "ufodata.drop(ufodata[ufodata.duplicated()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6ec8a",
   "metadata": {},
   "source": [
    "#### Impute missing values and remove the ones that cannot be imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7198f9",
   "metadata": {},
   "source": [
    "Verify that both 'city_latitude' and 'city_longitude' is all null given that 'city' is null, then, we can drop the rows where the city value is null. This is because there is no way to infer the geographic coordinate from the null city.\n",
    "\n",
    "i.e. if city==null AND city_latitude==null AND city_longitude==null, then remove those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6911283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if all(ufodata[ufodata['city'].isnull()]['city_latitude'].isnull()) and all(ufodata[ufodata['city'].isnull()]['city_longitude'].isnull()):\n",
    "    # take the rows where the city value is not null\n",
    "    ufodata = ufodata[ufodata['city'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b99b7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_state(cols):\n",
    "    '''\n",
    "    Impute state by using the value inside the last bracket from the city.\n",
    "    '''\n",
    "    \n",
    "    city = cols[0]\n",
    "    state = cols[1]\n",
    "    \n",
    "    if pd.isnull(state):\n",
    "        # get the phrase inside the last bracket\n",
    "        phrase = city.split('(')[-1].split(')')[0]\n",
    "        \n",
    "        # if no bracket found, return null\n",
    "        if phrase == city:\n",
    "            return np.nan\n",
    "        \n",
    "        # use nlp to get the country name\n",
    "        entities = nlp(phrase).ents\n",
    "        \n",
    "        # check if the phrase contains only 1 entity and that belongs to a country/state\n",
    "        if len(entities) == 1 and entities[0].label_ == 'GPE':\n",
    "            # then use that value as the state\n",
    "            return entities[0].text\n",
    "        # else return null\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    else:\n",
    "        return state\n",
    "    \n",
    "ufodata['state'] = ufodata[['city', 'state']].apply(impute_state, axis=1)\n",
    "\n",
    "# once the state value can be extracted from the city value\n",
    "# remove the rows where the state is still null\n",
    "ufodata = ufodata[ufodata['state'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdb9efb",
   "metadata": {},
   "source": [
    "#### Check for correct string formatting in the 'city' column, e.g. things like \"(in flight)\", \"between city1 and city2\", or \"unknown\" should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa0ac1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#************YOU MIGHT NEED TO DO:*****************\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "\n",
    "# remove all brackets in the city\n",
    "ufodata['city'] = ufodata['city'].apply(lambda x: x.split(' (')[0])\n",
    "\n",
    "def check_format(sent):\n",
    "    '''\n",
    "    Check the format of the city value,\n",
    "    if there is punctuation, then it is in bad format.\n",
    "    '''\n",
    "    \n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    if [w for w in sent if w in string.punctuation]:\n",
    "        return True\n",
    "\n",
    "# a new column 'city_bad_format' indicating True if the city string is in bad format\n",
    "ufodata['city_bad_format'] = ufodata['city'].apply(lambda x: check_format(x))\n",
    "\n",
    "\n",
    "def preprocess(sent):\n",
    "    '''\n",
    "    Tokenize the city string and tag those words.\n",
    "    '''\n",
    "    \n",
    "    sent = nltk.word_tokenize(sent)\n",
    "    sent = nltk.pos_tag(sent)\n",
    "    return sent\n",
    "\n",
    "\n",
    "def take_NNP(cols):\n",
    "    '''\n",
    "    Take only the proper nouns (NNP) in the city,\n",
    "    to get a proper format of the city string so that we can impute geocoordinates\n",
    "    using both city and state values.\n",
    "    \n",
    "    if bad_format==True and geocoord==null:\n",
    "        then fix the city string\n",
    "    if (bad_format==True and has geocoord) or no bad_format:\n",
    "        then return city\n",
    "    '''\n",
    "    \n",
    "    city = cols[0]\n",
    "    lat = cols[1]\n",
    "    lon = cols[2]\n",
    "    bad_format = cols[3]\n",
    "    \n",
    "    # the pattern is a noun phrase (NP) that consists of any number of NNPs\n",
    "    chunk_pattern = 'NP: {<NNP>*}'\n",
    "    cp = nltk.RegexpParser(chunk_pattern)\n",
    "    \n",
    "    # if the city string is in bad format\n",
    "    if bad_format:\n",
    "        # and I have either city_latitude or city_longitude is null,\n",
    "        # then want to take only the NNPs from the city\n",
    "        if pd.isnull(lat) or pd.isnull(lon):\n",
    "            city = preprocess(city)\n",
    "            \n",
    "            # chunk parser on the city\n",
    "            cc = cp.parse(city)\n",
    "\n",
    "            # create a list that stores all the NNPs\n",
    "            NNPlst = []\n",
    "            for subtree in cc.subtrees(filter=lambda t: t.label() == 'NP'):\n",
    "                for t in subtree:\n",
    "                    NNPlst.append(t[0])\n",
    "\n",
    "            # join the result\n",
    "            return ' '.join(NNPlst)\n",
    "        else:\n",
    "            return city\n",
    "        \n",
    "    else:\n",
    "        return city\n",
    "\n",
    "# fixing string formats in the city column\n",
    "ufodata['city'] = ufodata[['city', \n",
    "                           'city_latitude',\n",
    "                           'city_longitude',\n",
    "                           'city_bad_format']].apply(take_NNP, axis=1)\n",
    "ufodata.drop(['city_bad_format'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e778ed1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# after correcting the city format, remove rows with empty city strings\n",
    "# these are not null values but empty strings\n",
    "ufodata['empty_city'] = ufodata['city'].apply(lambda x: not x)\n",
    "ufodata = ufodata[ufodata['empty_city']==False]\n",
    "ufodata.drop(['empty_city'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46b2f35",
   "metadata": {},
   "source": [
    "#### Impute 'city_latitude' and 'city_longitude' values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb36f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_address(cols):\n",
    "    city = cols[0]\n",
    "    state = cols[1]\n",
    "    \n",
    "    return city + ', ' + state\n",
    "\n",
    "# create an 'address' column for geocoordinates imputation\n",
    "ufodata['address'] = ufodata[['city', 'state']].apply(get_address, axis=1)\n",
    "\n",
    "def get_geocoord(cols):\n",
    "    '''\n",
    "    Get geocoordinates of the city.\n",
    "    *** 40 minutes on GPU ***\n",
    "    '''\n",
    "    \n",
    "    lat = cols[0]\n",
    "    address = cols[1]\n",
    "\n",
    "    if pd.isnull(lat):\n",
    "        try:\n",
    "            location = geolocator.geocode(address)\n",
    "            return (location.point.latitude, location.point.longitude)\n",
    "        except:\n",
    "            return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# use 'address' to get 'geocoord'\n",
    "ufodata['geocoord'] = ufodata[['city_latitude', 'address']].apply(get_geocoord, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8fa81a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check null entries of city_latitude is the same as the null entries of city_longitude\n",
    "# then drop rows where both city_latitude and geocoord is null, this will also drop city_longitude\n",
    "# because if geocoord is null, then lat and lon cannot be imputed\n",
    "if all(ufodata['city_latitude'].isnull().index == ufodata['city_longitude'].isnull().index):\n",
    "    ufodata.drop(ufodata[ufodata['city_latitude'].isnull() & ufodata['geocoord'].isnull()].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24757250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_latitude(cols):\n",
    "    lat = cols[0]\n",
    "    geocoord = cols[1]\n",
    "    \n",
    "    if pd.isnull(lat):\n",
    "        return geocoord[0]\n",
    "    else:\n",
    "        return lat\n",
    "\n",
    "# use 'geocoord' to get 'city_latitude'\n",
    "ufodata['city_latitude'] = ufodata[['city_latitude', 'geocoord']].apply(impute_latitude, axis=1)\n",
    "\n",
    "def impute_longitude(cols):\n",
    "    lon = cols[0]\n",
    "    geocoord = cols[1]\n",
    "    \n",
    "    if pd.isnull(lon):\n",
    "        return geocoord[1]\n",
    "    else:\n",
    "        return lon\n",
    "\n",
    "# use 'geocoord' to get 'city_longitude'\n",
    "ufodata['city_longitude'] = ufodata[['city_longitude', 'geocoord']].apply(impute_longitude, axis=1)\n",
    "ufodata.drop(['geocoord', 'address'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9fdf00",
   "metadata": {},
   "source": [
    "#### Add a 'country_code' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e11426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_code(cols):\n",
    "    '''\n",
    "    Add a 'country_code' column to ufodata.\n",
    "    *** 1 hour on GPU ***\n",
    "    '''\n",
    "    \n",
    "    lat = cols[0]\n",
    "    lon = cols[1]\n",
    "    \n",
    "    try:\n",
    "        location = geolocator.reverse(str(lat)+', '+str(lon), addressdetails=True)\n",
    "        return location.raw.get('address', np.nan).get('country_code', np.nan)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# use 'city_latitude' and 'city_longitude' to get 'country_code'\n",
    "ufodata['country_code'] = ufodata[['city_latitude', 'city_longitude']].apply(get_country_code, axis=1)\n",
    "ufodata = ufodata[ufodata['country_code'].notnull()]\n",
    "ufodata['country_code'] = ufodata['country_code'].apply(lambda x: x.upper())\n",
    "\n",
    "# A SIDE WORK: fixing the country_code for Kosovo\n",
    "# ufodata[ufodata['country_code'] == 'XK']\n",
    "# geolocator.reverse('42.240125, 21.025334').raw\n",
    "# pycountry.countries.search_fuzzy('Kosovo')\n",
    "ufodata['country_code'].replace({\"XK\": \"RS\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f665b",
   "metadata": {},
   "source": [
    "#### Converting 'duration' into interval of seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a572e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with null duration values\n",
    "ufodata = ufodata[ufodata['duration'].notnull()]\n",
    "\n",
    "def get_duration_units(col):\n",
    "    '''\n",
    "    Get the time units from the 'duration' column:\n",
    "    i.e.:\n",
    "    min = minutes\n",
    "    sec = seconds\n",
    "    hour = hour\n",
    "    '''\n",
    "    \n",
    "    duration = col[0]\n",
    "    seconds = set(['s','e','c'])\n",
    "    minutes = set(['m','i','n'])\n",
    "    hours = set(['h','r'])\n",
    "    duration_chars = set([char for char in duration.lower()])\n",
    "    \n",
    "    if duration_chars.intersection(seconds) == seconds:\n",
    "        return 'sec'\n",
    "    elif duration_chars.intersection(minutes) == minutes:\n",
    "        return 'min'\n",
    "    elif duration_chars.intersection(hours) == hours:\n",
    "        return 'hour'\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# create a new column that contains only the time duration units\n",
    "ufodata['duration_units'] = ufodata[['duration']].apply(get_duration_units, axis=1)\n",
    "\n",
    "# drop rows with null duration_units\n",
    "# because having the number with no units, the number is meaningless\n",
    "ufodata = ufodata[ufodata['duration_units'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374ce7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_duration_digits(col):\n",
    "    '''\n",
    "    Get only the number part from the 'duration' column,\n",
    "    either 1 digit number or 2 digit number representing the length of that time units.\n",
    "    '''\n",
    "    \n",
    "    duration = col[0]\n",
    "    two_digit_num = re.compile('[0-9][0-9]')\n",
    "    one_digit_num = re.compile('[0-9]')\n",
    "    \n",
    "    # find 2 digit numbers first\n",
    "    if re.findall(two_digit_num, duration):\n",
    "        return float(re.findall(two_digit_num, duration)[0])\n",
    "    # then find 1 digit numbers\n",
    "    elif re.findall(one_digit_num, duration):\n",
    "        return float(re.findall(one_digit_num, duration)[0])\n",
    "    # return the number 1 if no digit found\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "# create a new column that contains only the number from 'duration' column\n",
    "ufodata['duration_digits'] = ufodata[['duration']].apply(get_duration_digits, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53aca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_total_seconds(cols):\n",
    "    '''\n",
    "    Conversion to interval of seconds.\n",
    "    '''\n",
    "    \n",
    "    units = cols[0]\n",
    "    digits = cols[1]\n",
    "    \n",
    "    if units == 'sec':\n",
    "        return digits\n",
    "    elif units == 'min':\n",
    "        return 60.0*digits\n",
    "    else:\n",
    "        return 3600.0*digits\n",
    "\n",
    "ufodata['duration'] = ufodata[['duration_units', 'duration_digits']].apply(get_total_seconds, axis=1)\n",
    "ufodata.drop(['duration', 'duration_units', 'duration_digits'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72508e93",
   "metadata": {},
   "source": [
    "#### Combine the shapes that share similar characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5dedc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check total types of unique shapes\n",
    "ufodata['shape'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a4b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null entries with 'unknown' value\n",
    "ufodata.fillna(value='unknown', inplace=True)\n",
    "\n",
    "other = ['unknown', 'other']\n",
    "formation = ['changing', 'formation', 'diamond']\n",
    "light = ['light', 'flash']\n",
    "cross = ['cross', 'chevron']\n",
    "triangle = ['triangle', 'teardrop', 'cone']\n",
    "oval = ['oval', 'egg']\n",
    "sphere = ['sphere', 'fireball']\n",
    "circle = ['circle', 'disk']\n",
    "rectangle = ['rectangle', 'cylinder', 'cigar']\n",
    "\n",
    "def category_consolidation(col):\n",
    "    '''\n",
    "    Consolidate the shape labels.\n",
    "    '''\n",
    "    \n",
    "    shape = col[0]\n",
    "    \n",
    "    if shape in other:\n",
    "        return 'other'\n",
    "    elif shape in formation:\n",
    "        return 'formation'\n",
    "    elif shape in light:\n",
    "        return 'light'\n",
    "    elif shape in cross:\n",
    "        return 'cross'\n",
    "    elif shape in triangle:\n",
    "        return 'triangle'\n",
    "    elif shape in oval:\n",
    "        return 'oval'\n",
    "    elif shape in sphere:\n",
    "        return 'sphere'\n",
    "    elif shape in circle:\n",
    "        return 'circle'\n",
    "    else:\n",
    "        return 'rectangle'\n",
    "\n",
    "ufodata['shape'] = ufodata[['shape']].apply(category_consolidation, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ef7860",
   "metadata": {},
   "source": [
    "#### Convert datetime to standard datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e001c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert datetime to standard datetime format\n",
    "ufodata['datetime'] = pd.to_datetime(ufodata['date_time'])\n",
    "ufodata.drop(['date_time'], axis=1, inplace=True)\n",
    "ufodata.set_index('datetime', inplace=True)\n",
    "ufodata.reset_index(inplace=True)\n",
    "\n",
    "# I want to create Year and Month columns for seasonal analysis later\n",
    "ufodata['Year'] = ufodata['datetime'].apply(lambda dt: dt.year)\n",
    "ufodata['Month'] = ufodata['datetime'].apply(lambda dt: dt.month)\n",
    "\n",
    "# sort the rows order by 'datetime'\n",
    "ufodata.sort_values(by=['datetime'], inplace=True)\n",
    "ufodata.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7c37ce",
   "metadata": {},
   "source": [
    "#### Finally, export the cleaned data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d0e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ufodata.to_csv('ufodata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ccb08e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
